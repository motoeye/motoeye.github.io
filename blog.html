<!DOCTYPE html>
<html >
<head>
  <meta charset="UTF-8">
  <title>MotoEye</title>
  
  
  
      <link rel="stylesheet" href="css/blogstyle.css">

  
</head>

<body>
  
<header>
  <div class="small" id="header-scroll">
    <h1><a href="#home">MotoEye</a></h1>
    <nav>
      <ul>
        <li><a href="index.html#home">HOME</a></li>
        <li><a href="index.html#about">BACKGROUND</a></li>
        <li><a href="index.html#project_detail">PRODUCT</a></li>
	      <li><a href="index.html#project_members">TEAM MEMBERS</a></li>
        <li><a href="blog.html">BLOG</a></li>
        <li><a href="mailto:mtecapstone2023@gmail.com">CONTACT US</a></li>
      </ul>
    </nav>
  </div>
</header>
<h4><u>BLOG</u></h4>

<div class="blog">
  <h5>Week 7: Ready, Set, Demo!</h5>
  <h3>March 6, 2023</h3>
  <div class="spacer">
    <hr>
  </div>
  <h2>Summary</h2>
  <p>Details coming later this week!</p>
  <br>
  <h6>Mechanical</h6>
  <p></p>
  <br>
  <h6>Electrical/Hardware</h6>
  <p></p>
  <br>
  <h6>Software</h6>
  <p></p>
</div>

<div class="blog">
  <h5>Week 6: Testing Complete</h5>
  <h3>February 25, 2023</h3>
  <div class="spacer">
    <hr>
  </div>
  <h2>Summary</h2>
  <p>After execution of a series of test plans in suitable riding conditions in the United States, MotoEye proved to
    be effective in its designed purpose. The test rider was successfully notified of impending forward facing obstacles 
    under designed detection distances and relative speeds.
  </p>
  <p><iframe src="img/motoeye-blog-video-week6.mp4" allowfullscreen="" width="90%" height="400" frameborder="0">
  </iframe></p>
</div>

<div class="blog">
  <h5>Week 5: Getting Ready for Testing</h5>
  <h3>February 16, 2023</h3>
  <div class="spacer">
    <hr>
  </div>
  <h2>Summary</h2>
  <p>All component sections work well as expected after total integration. At this point a first prototype is complete pending on road testing.</p>
  <br>
  <h6>Mechanical</h6>
  <p>All sides, base, and lid of the box were successfully laser cut. Custom L-brackets were 3D printed. Box was assembled along with all electrical
     components mounted and lid secured. Plan to paint acrylic after testing has been completed. </p>
  <br>
  <h6>Electrical/Hardware</h6>
  <p>Final power system wired together within box and being powered from a 12 V supply (the voltage of a motorcycle battery). Custom cables all working,
     including communication between camera and pi and both LEDs. Cable management completed for neatness within housing. Currently, the 
     status LED is hard wired to power pin of Raspberry Pi to indicate system power. </p>
  <br>
  <h6>Software</h6>
  <p>Final touches made on object detection algorithm, with filtering done for objects that are likely to be classified as obstacles on the road. 
     Integration with the GPIO firmware to light up the warning LED completed and was tested with human detection.  
     Relative velocity algorithm also implemented and tested with human interaction (LED should only turn on while walking quickly towards the camera i.e. higher relative velocity). 
     Software ready to be tested on the road! </p>
  <a>
    <img src="img/build_blog.jpg" width="300px" height="300px" class="center">
  </a>
</div>

<div class="blog">
  <h5>Week 4: Beginning to Integrate</h5>
  <h3>February 8, 2023</h3>
  <div class="spacer">
    <hr>
  </div>
  <h2>Summary</h2>
  <p>Progress in all sections are complete or near completion pending small challenges. Introductory steps of component integration has begun.</p>
  <br>
  <h6>Mechanical</h6>
  <p>More mechanical design changes made in order to enable assembly of separate laser cut acrylic sides of the box. Overall plan is to join 
    sides using custom 3D printed L-brackets and sealant (for water-proofing and extra security). All required fasteners purchased. Test laser cut completed.</p>
  <br>
  <h6>Electrical/Hardware</h6>
  <p>More custom cables built. Begin using Raspberry Pi as host computer for camera! In order to do this, a virtual environment was setup on the Pi where 
    all required libraries were installed, including OpenCV. Additional firmware was developed in order to light up test LEDs on a breadboard using the 
    GPIO pins of the Pi.</p>
  <br>
  <h6>Software</h6>
  <p>Begun development logic for lighting up LED when object detected in certain distance range. At this point, developemnt is incomplete due to challenges
    handling LED triggers for false and multiple object detection.</p>
  <a>
    <img src="img/ObjectDetection_blog.jpg" width="480px" height="200px" class="center">
  </a>
</div>

<div class="blog">
  <h5>Week 3: Development Continues</h5>
  <h3>January 31, 2023</h3>
  <div class="spacer">
    <hr>
  </div>
  <h2>Summary</h2>
  <p>Progress of development continues in all aspects of the project. Mechanical design changes are required for overall durability</p>
  <br>
  <h6>Mechanical</h6>
  <p>Small mechanical design change for how the lid will be mounted to the box. 3D printed the box in PLA (no lid) with success. All mounting holes 
    were confirmed to be dimensioned properly for electronics mounting. While torquing down screws, small deformities resulted in the PLA. 
    New approach -> laser cut acrylic as this material has a stronger yield strength </p>
  <br>
  <h6>Electrical/Hardware</h6>
  <p>Upgraded to Raspberry Pi 4 for wifi module capabilities. Started testing power system (DC-DC converter being used to power camera and Raspberry Pi). 
    Began constructing custom cables for system. Remote access to Pi over SSH achieved. </p>
  <br>
  <h6>Software</h6>
  <p>Reliability of object detection proved to be unreliable. Several datasets were tried as well as different neural networks. Upgrading to the
    Yolo V6 Nano Neutral network using the coco dataset provided most accurate detection. All hosting was primarily done on a laptop at this point.</p>
</div>

<div class="blog">
  <h5>Week 2: Initial Development Progress</h5>
  <h3>January 23, 2023</h3>
  <div class="spacer">
    <hr>
  </div>
  <h2>Summary</h2>
  <p>The depth detection of the recognized object was achieved using the camera.</p>
  <br>
  <h6>Software</h6>
  <p>The stereo depth features of the camera were explored. The depth function was implemented to calculate the depth/distance of the detected object from the camera. 
    This was achieved using the Yolo v5 deep neural network for obstacle detection. A sample of detection with respective dsitances  can be seen in the image below.</p>
  <a>
    <img src="\img\CameraOutput.png" width="300px" height="200px" class="center">
  </a>
</div>

<div class="blog">
  <h5>Week 1: Getting Started</h5>
  <h3>January 16, 2023</h3>
  <div class="spacer">
    <hr>
  </div>
  <h2>Summary</h2>
  <p>All major compoments are in hand. Initial setup and development has begun!</p>
  <br>
  <h6>Mechanical</h6>
  <p>The 3D printer has been set up and calibrated, awaiting our first test print.</p>
  <br>
  <h6>Electrical/Hardware</h6>
  <p>The raspberry pi model 3B+ board that will be used for our processor was flashed
    and loaded with the raspbian desktop operating system to begin inital development.
  </p>
  <br>
  <h6>Software</h6>
  <p>The camera was configured using depthAI sdk. A virtual environment was created to get an isolated environment for dependency management. The Camera output was 
    recognised, and had a 1 second lag. Testing for object detection was started using the Yolo v5 deep neural network.</p>
</div>

<div class="blog">
  <h5>Week 0: Summary of MTE 481</h5>
  <h3>January 9, 2022</h3>
  <div class="spacer">
    <hr>
  </div>
  <h2>Summary</h2>
  <p>By the end of MTE 481, all parts were ordered, some already in hand. At this point the team had a clear sense of direction given a comprehensive design plan
    for the various system subsections with a schedule in place for construction, testing and redesign as applicable.
  </p>
</div>

</body>
</html>
